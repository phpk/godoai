export default {
  common: {
    home: "Home",
    chat: "Chat",
    model: "Model",
    setting: "Setting",
    draw: "Draw",
    add: "Add",
    help:"Help",
    cancel: "Cancel",
    confim: "Confim",
    tips: "Tips",
    save: "Save",
    saveSuccess: "Save Success!",
    saveError: "Save Error!",
    uploadSuccess: "Upload Success!",
    uploadError: "Upload Error!",
    urlError: "The url is Error!",
    delete: "Delete",
    title: "Title",
    content: "Content",
    inputTitle: "Please input the title",
    cate: "Category",
    isDef: "Is Default?",
    description: "Description",
    faq: "FAQ",
    contact: "Contact Us",
    tos: "Terms of Service",
    policy: "Privacy Policy",
    cantStream: "Cannot read the stream",
    copySuccess: "Copy Success!"
  },
  index: {
    notFindChatModel: "The system did not detect a chat model. Would you like to download one?",
    modelManger: "ModelManagement",
    createChat: "CreateChat"

  },
  chat: {
    newchat: "New chat",
    title: "Config",
    apikey: "API Key",
    proxyUrl: "Proxy Url",
    proxyUrlPlaceholder: "Input your proxy url here.",
    apikeyPlaceholder: "If not input , the ApiKey in the .env will be used.",
    model: "Model",
    role: "Role",
    refknow: "Ref Knowledge",
    inputTitle: "Please input the chat title",
    selectModel: "Please choose a chatbot model",
    editsuccess: "Edited successfully!",
    addsuccess: "Added successfully!",
    notEyeModel: "The system did not detect any visual model. Would you like to download one?",
    uploadFile: "UploadFile",
    askme: "Ask Me Anything"
  },
  model: {
    cate: "Category",
    all: "All",
    chat: "Chat",
    code: "Code",
    img2txt: "Image2Txt",
    translation: "Translation",
    creation: "Creation",
    consultant: "Consultant",
    spoken: "Spoken",
    image: "Txt2Image",
    knowledge: "Knowledge",
    recording: "Recording",
    video: "Video",
    embed: "Embeding",
    embeddings: "Embeddings",
    tts: "Txt2Audio",
    audio: "Audio2Txt",
    assistant: "Assistant",
    search: "Search",
    labelDown: "Model Download",
    list: "Model List",
    chooseLabel: "Choose Label",
    downChanel: "Cancelled",
    hasDown: "Completed",
    noDown: "Incomplete",
    downloading: "Downloading",
    modelLabel: "ModelLabel",
    modelDown: "Download",
    help_label: "Choose category",
    help_labelDesc: "Select the model category you want to download",
    help_showdown: "View Download",
    help_showdownDesc: "Click here to view the download list and downloaded files",
    help_adddown: "Add a new download",
    help_adddownDesc: "Click here to add a new download, which is an advanced operation",
    help_addlabel: "Add new tags",
    help_addlabelDesc: "Click here to add a new tag. If there is no download list in the tag, it can be deleted",
    labelName: "Label Name",
    family: "Family",
    category: "Category",
    selectCategory: "Select Category",
    engine: "Engine",
    selectEngine: "Select Engine",
    chineseDescription: "ChineseDesc",
    englishDescription: "EnglishDesc",
    labelNameEmpty: "The label name cannot be empty.",
    local: "Local",
    network: "Network",
    invalidModel: 'Please enter a valid Model Address!',
    invalidContextLength: 'Please enter a valid Context length!',
    invalidModelUrl: 'Please enter a valid Model address!',
    invalidIp: 'Please enter a valid IP address!',
    fetchFailed: 'Failed to fetch models!',
    selectSource: 'Select Source',
    modelName: 'Model Name',
    selectLabel: 'Select Label',
    oppositeIpAddress: 'Opposite IP Address',
    selectModel: 'Select Model',
    modelUrl: 'Model URL',
    template: 'Template',
    contextLength: 'Context Length',
    parameterSettings: 'Parameter Settings',
    parameterSize: 'Parameter Size',
    selectQuantization: 'Select Quantization',
    enterModelName: 'Enter model name',
    enterIpAddress: 'Enter IP address',
    enterModelUrl: 'Model download URL, one per line, supports local absolute path',
    enterContextLength: 'Enter the context length of the model',
    onePerLine: 'One per line',
    enterParameterSize: 'Enter the size of the model parameters, 1.5B or 7B...',
    modelNames: 'Model Name:',
    modelSize: 'Model Size:',
    modelEngine: 'Model Engine:',
    applicableScope: 'Applicable Scope:',
    contextLengths: 'Context Length:',
    parameterSizes: 'Parameter Size:',
    requiredCPU: 'Required CPU:',
    requiredGPU: 'Required GPU:',
    modelTemplate: 'Model Template:',
    modelParameters: 'Model Parameters:'
  },
  setting: {
    modelSetting: "Model Setting",
    systemSetting: "System Config",
    defModel: "Default Model",
    chatSetting: "Chat Setting",
    serverUrl: "Server Url",
    chatModel: "ChatModel",
    eyeModel: "EyeModel",
    transModel: "TranslationModel",
    chooseModel: "Choose Model",
    switchLang: "Switch Language",
    switchStyle: "Switch Style",
    clearSystem: "Clear system data and reset all settings, the model will not be deleted",
    dataDir: "Data Dir",
    localDirHolder: "Local storage address, empty will use default address",
    contextLength: "contextLength",
    num_predict: "num_predict",
    num_keep: "num_keep",
    top_k: "top_k",
    top_p: "top_p",
    temperature: "temperature",
    tips_dataDir: `It is the data directory of the model server, used to store model files, cache files, log files, etc. The default is the .godoos/data folder located in the system user directory. If you want to change the address, please move the original directory folder to the new location.`,
    tips_apiUrl: `The API address is the API address of the model server, used to send requests to the model server. You can change it to another address, but you need to ensure that the model server can access that address.`,
    tips_contextLength: `The number of contexts can effectively control the memory ability of the model, but the larger the number of contexts, the slower the model will be, so it needs to be optimized according to the actual situation.`,
    tips_top_k: `Top_k is a parameter used in text generation models that controls the range of probability distributions considered when generating the next token. Specifically, the model will only select from the top k tokens with the highest probability, ignoring the remaining low probability tokens. This parameter directly affects the diversity and randomness of the generated text. The value range of top_k is usually a positive integer, including all integers 1 and above.<br /> Specifically, the minimum value is 1, which means that the model always selects the token with the highest probability, and the generated text will be very deterministic with almost no randomness. Maximum value: In theory, there is no upper limit, but in practical applications, there is usually a reasonable upper limit, such as 50, 100, or even higher, depending on the model and application scenario.<br /> Excessive top_k values may increase computational costs and introduce excessive noise, affecting the quality of the generated text.`,
    tips_top_p: `Among the parameters of the large model, top_p is a sampling strategy used for text generation diversity and controllability. It filters out the least likely tokens whose sum of probabilities reaches a certain threshold p, and only samples from the remaining tokens<br /> The function of this parameter is to allow for more diverse generation while limiting the occurrence of extremely low probability events, thereby improving the quality and rationality of the generated text<br /> When set to 1, it is equivalent to not performing any filtering, and the model will directly sample based on the probability distribution. The smaller the value, the stricter the filtering, and the generated results will be more concentrated on tokens with higher probabilities.`,
    tips_temperature: `Temperature is a parameter used to control the randomness of the language model's output text. This parameter affects the model's tendency to choose tokens under different probability distributions when generating text:<br/>Low temperature (close to 0): The text generated by the model will be more conservative, tend to choose the token with the highest probability, generate more predictable text, have higher repeatability, but may also be more "mediocre" or "templated"< High temperature (close to 1 but less than 1): Increasing the temperature will give the model more opportunities to choose lower probability options when selecting tokens, resulting in more diverse and innovative text, but it may also be more discrete, difficult to predict, and even produce semantic jumps or illogical sentences.`,
    tips_frequency_penalty: `Frequency_penalty is a parameter used in some language generation models to adjust the frequency impact of words in generated text, aiming to promote text diversity and reduce repetition by penalizing high-frequency words. The introduction of this parameter can help prevent the model from constantly repeating the same words or phrases when generating long texts<br /> Negative number: Reducing frequency penalty may increase the probability of high-frequency words appearing, sometimes used to encourage repetition of specific vocabulary to maintain coherence or emphasize<br />0: indicates no frequency penalty, and the model generation does not consider the influence of word frequency<br /> Positive numbers: Increase frequency penalties, reduce the probability of high-frequency words appearing, encourage models to explore more diverse expressions, and reduce text repetition.`,
    tips_presence_penalty: `Presence_penalty is another parameter in language generation models that controls the characteristics of generated text, mainly used to penalize or encourage specific tokens (words or phrases) that appear in the text. Unlike frequency_penalty, which focuses on word frequency, presence_penalty has a greater impact on whether the model includes certain words, rather than just their frequency of occurrence<br /> Negative numbers: Reducing the presence penalty may encourage the model to include more unique words or concepts, even if they are not the highest probability choices, which helps to enhance the diversity of the text<br />0: indicates that there is no penalty and the model does not impose any additional influence on the uniqueness of words during generation<br /> Positive number: Increasing the presence penalty, the model will try to avoid using words that have already appeared in the generated text, promoting the generated text to cover a wider range of topics or vocabulary.`,
    tips_num_predict: `Num_predict usually refers to specifying the number of tokens or prediction steps generated by the model in text generation tasks. Simply put, it specifies the length of the generated text, usually in tokens (which may be words, subwords, or other units depending on the model)<br /> Minimum value 1: Indicates the generation of at least one token of text, which may not be meaningful in practical applications unless the output of the model is highly structured and a single token can constitute complete information<br />  Maximum value of 5000: Maximum generated length, suitable for generating shorter text segments such as short answers, summaries, or short sentences. In practical applications, the specific range of num_predict values should be set based on the model's capabilities, the requirements of the application scenario, and resource constraints such as computational costs and response time. For tasks that require generating longer text, such as article creation, story generation, etc., the upper limit of num_predict may be set higher, such as hundreds or even thousands. However, it should be noted that as the generation length increases, not only will the computational cost increase, but the coherence and quality control of the generated text will also become more complex.`,
    tips_num_keep: `The value of num_ceep can affect the correlation and coherence between the generated text and the original input. A larger num_ceep value helps maintain continuity and consistency between the generated content and input, while a smaller value may allow the model to generate more free and varied text.`,
    
  },
  prompt: {
    cate: "Category",
    all: "All",
    chat: "Chat",
    translation: "Translation",
    spoken: "Spoken",
    creation_system: "Creation System",
    creation_leader: "Creation Leader",
    creation_builder: "Creation Assistant",
    knowledge: "Knowledge",
    contDelete: "The default system Prompt cannot be deleted!",
    delSuccess: "Delete Success!"
  },
  creation: {
    loading: 'Paragraph generation in progress, please try again later.',
    emptyTitle: 'Title cannot be empty',
    emptyParagraph: 'Paragraph content cannot be empty',
    selectText: 'Please select paragraph text',
    noModel: 'The system does not detect a chat model, please download one in model management!',
    error: '{message}',
    emptyContent: 'Content cannot be empty',
    saved: 'Saved successfully',
    outline: 'outline',
    titlePlaceholder: 'Enter Title',
    generateParagraph: 'Generate Paragraph',
    generateSelected: 'Generate Selected',
    generateAll: 'Generate All',
    save: 'Save',
    titleInput: 'Input Title',
    descriptionInputTitle: 'First, enter the title you want to create.',
    chooseCategory: 'Choose Category',
    descriptionChooseCategory: 'Select the category you want to create. If it does not exist, you can add it yourself.',
    operationButtons: 'Operation Buttons',
    descriptionOperationButtons: 'You can generate paragraphs, generate selected paragraphs, or generate all paragraphs.',
    saveData: 'Save',
    descriptionSaveData: 'You can save your created content for future continuation.',
    viewList: 'View List',
    descriptionViewList: 'Click here to view your past creation list.',
    model: 'Model',
    sysPrompt: 'System Prompt',
    sysPromptContent: 'System Content',
    outlinePrompt: 'Outline Prompt',
    outlinePromptContent: 'Outline Content',
    contentPrompt: 'Content Prompt',
    contentPromptContent: 'Content Content',
  },
  sd: {
    noImageModel: 'The system has not detected an image model, please download from model management.',
    modelNotExist: 'Model does not exist!',
    textToImage: 'Text to Image',
    imageToImage: 'Image to Image',
    models: 'Models',
    imgList: 'ImageList',
    uploadImg: 'Upload Image',
    invalidPrompt: "The prompt word cannot be empty",
    promptTitle: 'Prompt',
    promptPlaceholder: 'Prompt',
    widthTitle: 'Width',
    heightTitle: 'Height',
    moreSettingsTitle: 'More Settings',
    stepsTitle: 'Steps',
    numImagesTitle: 'Number of Images',
    cfgScaleTitle: 'Prompt Relevance',
    strengthTitle: 'Noise Reduction Strength',
    seedTitle: 'Seed',
    samplerTitle: 'Sampler',
    negativePromptTitle: 'Negative Prompt',
    negativePromptPlaceholder: 'Negative Prompt',
    generateButtonText: 'Generate'
  },
  knowledge: {
    pleaseInputKnowledgeBaseName: 'Please input knowledge base name',
    pleaseSelectEmbeddingModel: 'Please select embedding model',
    pleaseInputContextLength: 'Please input context length',
    pleaseSelectChatModel: 'Please select chat model',
    pleaseInputApiUrl: 'Please input apiUrl',
    knowledgeBaseName: 'Knowledge Base Name',
    embeddingModel: 'Embedding Model',
    chatModel: 'Chat Model',
    databaseEngine: 'Database Engine',
    engineAddress: 'Engine Address',
    sliceLength: 'Slice Length',
    duplicateFilenames: 'There are duplicate filenames',
    noFilesUploaded: 'No files have been uploaded.',
    uploadFailed: 'File upload failed.',
    uploadError: 'Upload error',
    uploadSuccess: 'Upload successful, conversion starting.',
    transferSuccess: 'Transfer success',
    deleteError: 'Deletion failed',
    deleteSuccess: 'Deletion successful.',
    invalidUrl: "Invalid Url",
    addUrl: "Add Url",
    mangerKnowledge: "Manger",
    defPrompt:"You are a versatile AI assistant, please answer my questions seriously"
  },
  spoken: {
    systemWelcome: 'Imagine we are friends, having a relaxed and fun conversation. We can chat about weather, music, movies, sports, or daily life topics. Feel free to interact with me and respond to my questions, let\'s communicate naturally like friends. And I know multiple languages, I will communicate with you in different languages, for example, if my current question is in Chinese, I hope your next answer is in Chinese, if my current question is in English, your next answer is in English, if my current question is in Chinese, your next answer is in Chinese.',
    requestFailed: 'Request failed',
    downloadTTSFirst: 'Please download the text-to-speech model first',
    downloadVocieFirst: 'Please download the speech-to-text model first',
    downloadTextFirst: 'Please download the chat model first',
  },
  recording: {
    newRecording:"New Recording",
    inputName: 'Please enter a name',
    name: 'Name',
    location: 'Location',
    meetingName: 'Please fill in the meeting name',
    meetingLocation: 'Please fill in the meeting location',
    time: 'Time',
    meetingTime: 'Please fill in the meeting time',
    remarks: 'Remarks',
    meetingRemarks: 'Please fill in the meeting remarks',
  },
  updatePrompt: {
    title: "Update Notice",
    versionFound: "A new version has been found: {versionTag}. Should we update?"
  }
}